{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import struct\n",
    "import csv\n",
    "import numpy as np\n",
    "import IPython.display as disp\n",
    "\n",
    "print \"modules loaded\"\n",
    "\n",
    "sdate = '20150417'\n",
    "spath = '/home/duxbury/ipython/user/'+sdate+'/'\n",
    "sconnect = spath + 'lda_scores.csv'\n",
    "topct = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!cat $sconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing line  500\n",
      " \"set hive.cli.print.header=true; SELECT tstart as tstart,sip as srcip,dip as dstip,sport as sport,dport as dport,proto as proto,flag as flags,stos as TOS,ibyt as bytes, ipkt as pkts,input as input, output as output from netflow_poc WHERE ( (sip='222.92.56.26' AND dip='134.134.139.72') OR (sip='134.134.139.72' AND dip='222.92.56.26') ) AND day='17' AND hour='03' AND minute(tstart)=25 SORT BY tstart LIMIT 100 \"  > /home/hadoop/ipython/user/20150417/edge-222_92_56_26-134_134_139_72-03-25_tst.tsv\n",
      "15/08/10 12:47:08 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.\n"
     ]
    }
   ],
   "source": [
    "#sev,tstart,srcIP,dstIP,sport,dport,proto,ipkt,ibyt,lda_score\n",
    "conns_list = []\n",
    "with open(sconnect, 'r') as f:\n",
    "    reader = csv.reader(f,delimiter=',') \n",
    "    reader.next();\n",
    "    rowct = 1\n",
    "    for row in reader:\n",
    "        if int(row[0]) < 3: # 3 is the don't care\n",
    "            # get src ip and dst ip\n",
    "            sip = row[2]\n",
    "            dip = row[3]\n",
    "            # get hour and date 2014-07-08 10:10:40\n",
    "            print row[1]\n",
    "            hr = row[1].split(' ')[1].split(':')[0]\n",
    "            dy = row[1].split(' ')[0].split('-')[2] \n",
    "            mm = row[1].split(' ')[1].split(':')[1]\n",
    "            #TODO: using netflow_avro table, this query should change - no more minute(), hour()\n",
    "            # also, there are more columns to return           \n",
    "            conn = (sip,dip,dy,hr,mm)\n",
    "            if conn not in conns_list:\n",
    "                conns_list.append(conn)                    \n",
    "\n",
    "            if rowct == topct:\n",
    "                break\n",
    "            rowct = rowct + 1\n",
    "\n",
    "for conn in conns_list:\n",
    "    sip = conn[0]\n",
    "    dip = conn[1]\n",
    "    dy = conn[2]\n",
    "    hr = conn[3]\n",
    "    mm = conn[4]\n",
    "    \n",
    "    hivestr = (\" \\\"set hive.cli.print.header=true; SELECT treceived as tstart,sip as srcip,\" +\n",
    "    \"dip as dstip,sport as sport,dport as dport,proto as proto,flag as flags,stos as TOS,\" +\n",
    "    \"ibyt as bytes, ipkt as pkts,input as input, output as output from netflow\" + \n",
    "    \" WHERE ( (sip=\\'\" + sip + \"\\' AND dip=\\'\" + dip + \"\\') OR \" +\n",
    "    \"(sip=\\'\" + dip + \"\\' AND dip=\\'\" + sip + \"\\') ) AND trday=\"+dy+\" AND trhour=\"+hr +\n",
    "    \" AND trminute=\"+mm +\" SORT BY tstart LIMIT 100 \\\"  > \" + spath+ \"edge-\" + sip.replace(\".\",\"_\") + \"-\" + \n",
    "    dip.replace(\".\",\"_\") + \"-\" + hr + \"-\" + mm + \"_tst.tsv\")\n",
    "    disp.clear_output()\n",
    "    print 'processing line ',rowct\n",
    "    print hivestr\n",
    "    !hive -S -e $hivestr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n"
     ]
    }
   ],
   "source": [
    "#sev,tstart,srcIP,dstIP,sport,dport,proto,ipkt,ibyt,lda_score\n",
    "srcdict = {}\n",
    "rowct = 1\n",
    "with open(sconnect, 'r') as f:\n",
    "    reader = csv.reader(f,delimiter=',') \n",
    "    reader.next();\n",
    "    rowct = 1\n",
    "    for row in reader:\n",
    "        if row[2] in srcdict:\n",
    "            srcdict[row[2]] += 1\n",
    "        else:\n",
    "            srcdict[row[2]] = 1\n",
    "        if row[3] in srcdict:\n",
    "            srcdict[row[3]] += 1\n",
    "        else:\n",
    "            srcdict[row[3]] = 1\n",
    "        rowct += 1\n",
    "        if rowct == topct:\n",
    "            break\n",
    "print len(srcdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing line  1\n",
      " \"set hive.cli.print.header=true; SELECT sip as srcip,dip as dstip, MAX(ibyt) as maxbyte, AVG(ibyt) as avgbyte,  MAX(ipkt) as maxpkt, AVG(ipkt) as avgpkt  from netflow_poc WHERE day='23' AND ( (sip='176.109.224.84' AND dip IN('134.134.137.73','192.55.54.38','134.134.139.74') OR sip IN('134.134.137.73','192.55.54.38','134.134.139.74') AND dip='176.109.224.84') )  GROUP BY sip,dip \"  > /home/hadoop/ipython/user/20150423/chord-176_109_224_84.tsv\n",
      "15/06/16 08:57:22 WARN conf.HiveConf: DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.\n"
     ]
    }
   ],
   "source": [
    "ipct = 1\n",
    "for ip in srcdict:\n",
    "    rowct = 1\n",
    "    if srcdict[ip] > 1:\n",
    "        # get src ip and dst ip\n",
    "        # iterate through the list again for any risk value > 3\n",
    "        # build a dstdict of keys\n",
    "        dstdict = {}\n",
    "        with open(sconnect, 'r') as f:\n",
    "            reader = csv.reader(f,delimiter=',') \n",
    "            reader.next();\n",
    "            for row in reader:\n",
    "                if ip == row[2]:\n",
    "                    dstdict[row[3]]=row[3]\n",
    "                if ip == row[3]:\n",
    "                    dstdict[row[2]]=row[2]\n",
    "                rowct += 1\n",
    "                if rowct == topct:\n",
    "                    break        \n",
    "        # query hive with aggregated query \n",
    "        if len(dstdict.keys()) > 1:\n",
    "            dstip = \"'%s',\"*len(dstdict.keys()) % tuple(dstdict.keys())\n",
    "            hivestr = (\" \\\"set hive.cli.print.header=true; SELECT sip as srcip,\" +\n",
    "            \"dip as dstip, MAX(ibyt) as maxbyte, AVG(ibyt) as avgbyte,  MAX(ipkt) as maxpkt, AVG(ipkt) as avgpkt \" +\n",
    "            \" from netflow\" +  \n",
    "            \" WHERE trday=\"+dy+\" AND ( (sip=\\'\" + ip + \"\\' AND dip IN(\"+ dstip[:-1] + \")\"\n",
    "            \" OR sip IN(\" + dstip[:-1] + \") AND dip=\\'\" + ip + \"\\') ) \" +\n",
    "            \" GROUP BY sip,dip \\\"  > \" + spath + \"chord-\" + ip.replace(\".\",\"_\") + \".tsv\")\n",
    "            disp.clear_output()\n",
    "            print 'processing line ',ipct\n",
    "            print hivestr\n",
    "            !hive -S -e $hivestr\n",
    "    if ipct == topct:\n",
    "        break\n",
    "    ipct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "\n",
    "chordfiles = []\n",
    "for (dirpath, dirnames, filenames) in walk(spath):\n",
    "    for files in filenames:\n",
    "        if files.startswith(\"chord-\") and files.endswith(\".tsv\"):\n",
    "            chordfiles.extend([files])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ceate chord matrix\n",
    "for chordfile in chordfiles:\n",
    "    #chordfile = 'chord-10_0_0_9'\n",
    "    ll = 15;\n",
    "    #load csv into array\n",
    "    #with open(spath+chordfile+'.tsv', 'rb') as f:\n",
    "    with open(spath+chordfile, 'rb') as f:\n",
    "        reader = csv.reader(f,delimiter='\\t') \n",
    "        reader.next()\n",
    "        carry = np.zeros([ll,3],np.int64)\n",
    "        rowct = 0\n",
    "        for row in reader:\n",
    "            carry[rowct,0] = struct.unpack(\"!L\", socket.inet_aton(row[0]))[0]    \n",
    "            carry[rowct,1] = struct.unpack(\"!L\", socket.inet_aton(row[1]))[0]    \n",
    "            carry[rowct,2] = np.float32(row[3])\n",
    "            rowct += 1\n",
    "            if rowct == ll-1:\n",
    "                break\n",
    "\n",
    "    dim = np.zeros(2*ll,np.int64)\n",
    "    dim = np.concatenate([carry[:,0],carry[:,1]],axis=0)\n",
    "    dim = np.unique(dim)\n",
    "    #print dim\n",
    "    chordm = np.zeros([len(dim),len(dim)],np.int64)\n",
    "    for j in carry:\n",
    "        xcoord = np.where(dim == j[0]);\n",
    "        ycoord = np.where(dim == j[1]);\n",
    "        chordm[xcoord,ycoord] = j[2]\n",
    "   \n",
    "    dimstr = []\n",
    "    for j in dim:\n",
    "        dimstr.append(socket.inet_ntoa(struct.pack('!L', j)))\n",
    "    headr = \",\".join(dimstr)\n",
    "    fmtr = r'%1d ' * len(dim)\n",
    "    #with open(spath+chordfile+'.csv', 'wb') as f:\n",
    "    with open(spath+chordfile.replace('.tsv','.csv'), 'wb') as f:\n",
    "        riter = csv.writer(f,delimiter=',')\n",
    "        # header line?\n",
    "        for j in chordm:\n",
    "            #outstr = '['+','.join(map(str, j))+'],'\n",
    "            riter.writerow(j)\n",
    "    #np.savetxt(g,chordm,delimiter=',',fmt=fmtr,header=headr)\n",
    "print 'chord data loaded.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
